#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è AI Digest –≤ Notion

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
1. –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É "AI Digest - Week X YEAR" –≤ Database "–õ–∏—á–Ω—ã–π –±–ª–æ–≥"
2. –ó–∞–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —à–∞–±–ª–æ–Ω —Å —Å–µ–∫—Ü–∏—è–º–∏ Research, Notes, Draft
3. –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Database "–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è" –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
4. –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –¥–∞—Ç–∞–º –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ —Å–µ–∫—Ü–∏—é Draft
"""

import os
import re
import sys
import httpx
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from collections import defaultdict
from notion_client import Client


def extract_database_id(url_or_id: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç Database ID –∏–∑ URL –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID –∫–∞–∫ –µ—Å—Ç—å

    Args:
        url_or_id: URL Database –∏–ª–∏ Database ID

    Returns:
        Database ID (32 —Å–∏–º–≤–æ–ª–∞)
    """
    if not url_or_id:
        return ""

    url_or_id = url_or_id.strip()

    # –ï—Å–ª–∏ —ç—Ç–æ URL, –∏–∑–≤–ª–µ–∫–∞–µ–º ID
    if url_or_id.startswith('http'):
        # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        url_without_params = url_or_id.split('?')[0].split('#')[0]

        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç URL
        parts = url_without_params.rstrip('/').split('/')
        if len(parts) > 0:
            last_part = parts[-1]
            # –£–±–∏—Ä–∞–µ–º –¥–µ—Ñ–∏—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª–∏–Ω—ã
            id_without_dashes = last_part.replace('-', '')
            if len(id_without_dashes) == 32:
                return last_part

    # –ï—Å–ª–∏ —ç—Ç–æ ID –Ω–∞–ø—Ä—è–º—É—é
    id_without_dashes = url_or_id.replace('-', '')
    if len(id_without_dashes) == 32:
        return url_or_id

    return url_or_id


class TitleVerifier:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π"""

    def __init__(self, max_concurrent: int = 5):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.max_concurrent = max_concurrent

    def detect_site_type(self, url: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å–∞–π—Ç–∞ –ø–æ URL"""
        domain = urlparse(url).netloc.lower()

        if 'vc.ru' in domain:
            return 'vcru'
        elif 'techcrunch.com' in domain:
            return 'techcrunch'
        elif 'habr.com' in domain:
            return 'habr'
        else:
            return 'unknown'

    def extract_title_from_soup(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ HTML –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–∞–π—Ç–∞"""
        site_type = self.detect_site_type(url)

        if site_type == 'vcru':
            title_tag = soup.find('h1', class_=lambda x: x and 'content-title' in x)
            if title_tag:
                # –£–¥–∞–ª—è–µ–º –∏–∫–æ–Ω–∫–∏
                title_copy = BeautifulSoup(str(title_tag), 'html.parser')
                for icon in title_copy.find_all('span', class_='content-title__editorial-icon'):
                    icon.decompose()
                for svg in title_copy.find_all('svg'):
                    svg.decompose()
                for use in title_copy.find_all('use'):
                    use.decompose()
                title = title_copy.get_text(separator=' ', strip=True)
                return re.sub(r'\s+', ' ', title).strip()

        elif site_type == 'techcrunch':
            title_tag = soup.find('h1', class_='wp-block-post-title')
            if title_tag:
                return title_tag.get_text(strip=True)

        elif site_type == 'habr':
            title_tag = soup.find('h1', class_='tm-title')
            if title_tag:
                span = title_tag.find('span')
                if span:
                    return span.get_text(strip=True)
                return title_tag.get_text(strip=True)

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        for tag in ['h1', 'title']:
            title_tag = soup.find(tag)
            if title_tag:
                return title_tag.get_text(strip=True)

        return None

    async def fetch_title(self, session: aiohttp.ClientSession, url: str) -> Tuple[str, Optional[str], Optional[str]]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç title —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ URL

        Returns:
            Tuple[url, title, error]
        """
        try:
            async with session.get(url, headers=self.headers, timeout=aiohttp.ClientTimeout(total=15)) as response:
                response.raise_for_status()
                content = await response.read()
                soup = BeautifulSoup(content, 'html.parser')
                title = self.extract_title_from_soup(soup, url)
                return (url, title, None)
        except aiohttp.ClientError as e:
            return (url, None, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        except Exception as e:
            return (url, None, f"–û—à–∏–±–∫–∞: {e}")

    def normalize_title(self, title: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not title:
            return ""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        normalized = title.lower()
        normalized = re.sub(r'\s+', ' ', normalized)
        normalized = normalized.strip()
        return normalized

    def titles_match(self, digest_title: str, actual_title: str, threshold: float = 0.7) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π

        Args:
            digest_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–∑ Digest
            actual_title: –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (0.0 - 1.0)

        Returns:
            True –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç
        """
        if not digest_title or not actual_title:
            return False

        norm_digest = self.normalize_title(digest_title)
        norm_actual = self.normalize_title(actual_title)

        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if norm_digest == norm_actual:
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –≤ –¥—Ä—É–≥–æ–µ
        if norm_digest in norm_actual or norm_actual in norm_digest:
            return True

        # –†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        digest_words = set(norm_digest.split())
        actual_words = set(norm_actual.split())

        if not digest_words or not actual_words:
            return False

        common_words = digest_words & actual_words
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        min_size = min(len(digest_words), len(actual_words))
        similarity = len(common_words) / min_size if min_size > 0 else 0

        return similarity >= threshold

    async def verify_titles_async(self, news_items: List[Dict], log_file: Optional[str] = None) -> List[Dict]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π

        Args:
            news_items: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–ª—è–º–∏ name –∏ url
            log_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π [{name, url, actual_title, error}]
        """
        mismatches = []
        all_results = []  # –î–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        items_with_urls = [(item['name'], item['url']) for item in news_items if item.get('url')]

        if not items_with_urls:
            return mismatches

        async with aiohttp.ClientSession() as session:
            semaphore = asyncio.Semaphore(self.max_concurrent)

            async def fetch_with_semaphore(name: str, url: str) -> Dict:
                async with semaphore:
                    url_result, actual_title, error = await self.fetch_title(session, url)
                    return {
                        'name': name,
                        'url': url,
                        'actual_title': actual_title,
                        'error': error
                    }

            tasks = [fetch_with_semaphore(name, url) for name, url in items_with_urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in results:
                if isinstance(result, Exception):
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
                if result.get('error'):
                    match_status = 'ERROR'
                    is_match = False
                elif result.get('actual_title'):
                    is_match = self.titles_match(result['name'], result['actual_title'])
                    match_status = 'MATCH' if is_match else 'MISMATCH'
                else:
                    match_status = 'NO_TITLE'
                    is_match = False

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                all_results.append({
                    'name': result['name'],
                    'url': result['url'],
                    'actual_title': result.get('actual_title'),
                    'error': result.get('error'),
                    'status': match_status
                })

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                if result.get('error'):
                    mismatches.append({
                        'name': result['name'],
                        'url': result['url'],
                        'actual_title': None,
                        'error': result['error']
                    })
                elif result.get('actual_title') and not is_match:
                    mismatches.append({
                        'name': result['name'],
                        'url': result['url'],
                        'actual_title': result['actual_title'],
                        'error': None
                    })

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
        if log_file:
            self._write_log(log_file, all_results)

        return mismatches

    def _write_log(self, log_file: str, results: List[Dict]):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –ª–æ–≥-—Ñ–∞–π–ª"""
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"# –õ–æ–≥ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π\n")
            f.write(f"# –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {len(results)}\n")

            match_count = sum(1 for r in results if r['status'] == 'MATCH')
            mismatch_count = sum(1 for r in results if r['status'] == 'MISMATCH')
            error_count = sum(1 for r in results if r['status'] == 'ERROR')

            f.write(f"# –°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {match_count}\n")
            f.write(f"# –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {mismatch_count}\n")
            f.write(f"# –û—à–∏–±–æ–∫: {error_count}\n")
            f.write("=" * 80 + "\n\n")

            for i, result in enumerate(results, 1):
                status_icon = {
                    'MATCH': '‚úÖ',
                    'MISMATCH': '‚ùå',
                    'ERROR': '‚ö†Ô∏è',
                    'NO_TITLE': '‚ùì'
                }.get(result['status'], '?')

                f.write(f"{i}. [{result['status']}] {status_icon}\n")
                f.write(f"   URL: {result['url']}\n")
                f.write(f"   –ù–∞–∑–≤–∞–Ω–∏–µ –≤ Digest:    {result['name']}\n")
                if result.get('error'):
                    f.write(f"   –û—à–∏–±–∫–∞: {result['error']}\n")
                elif result.get('actual_title'):
                    f.write(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {result['actual_title']}\n")
                else:
                    f.write(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: (–Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å)\n")
                f.write("\n")

    def verify_titles(self, news_items: List[Dict], log_file: Optional[str] = None) -> List[Dict]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏–π"""
        return asyncio.run(self.verify_titles_async(news_items, log_file))


class DigestCreator:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è AI Digest –≤ Notion"""

    def __init__(self, notion_token: str, blog_db_id: str, news_db_id: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

        Args:
            notion_token: API —Ç–æ–∫–µ–Ω Notion
            blog_db_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö "–õ–∏—á–Ω—ã–π –±–ª–æ–≥"
            news_db_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö "–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
        """
        self.notion = Client(auth=notion_token)
        self.notion_token = notion_token
        self.blog_db_id = blog_db_id
        self.news_db_id = news_db_id

    def get_current_week_info(self) -> Tuple[int, int]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–π –Ω–µ–¥–µ–ª–∏ –∏ –≥–æ–¥

        Returns:
            Tuple[week_number, year]
        """
        now = datetime.now()
        week_number = now.isocalendar()[1]
        year = now.year
        return week_number, year

    def create_digest_page(self, week_number: int, year: int) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É AI Digest –≤ Database "–õ–∏—á–Ω—ã–π –±–ª–æ–≥"

        Args:
            week_number: –ù–æ–º–µ—Ä –Ω–µ–¥–µ–ª–∏
            year: –ì–æ–¥

        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        title = f"AI Digest - Week {week_number} {year}"

        # Properties –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        properties = {
            "Name": {
                "title": [
                    {
                        "type": "text",
                        "text": {"content": title}
                    }
                ]
            },
            "Type": {
                "select": {"name": "Blog Post"}
            },
            "–¢–µ–º–∞—Ç–∏–∫–∞": {
                "multi_select": [{"name": "–ù–æ–≤–æ—Å—Ç–∏"}]
            },
            "Status": {
                "select": {"name": "In Progress"}
            }
        }

        # –®–∞–±–ª–æ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        template_blocks = self._create_template_blocks()

        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        response = self.notion.pages.create(
            parent={"database_id": self.blog_db_id},
            properties=properties,
            children=template_blocks
        )

        page_id = response["id"]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –≤ toggle –±–ª–æ–∫–∏
        self._populate_toggle_blocks(page_id)

        return page_id

    def _populate_toggle_blocks(self, page_id: str):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –≤ toggle –±–ª–æ–∫–∏ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Args:
            page_id: ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –±–ª–æ–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        blocks_response = self.notion.blocks.children.list(block_id=page_id)
        blocks = blocks_response.get("results", [])

        # –ù–∞—Ö–æ–¥–∏–º toggle –±–ª–æ–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∏—Ö –∫–æ–Ω—Ç–µ–Ω—Ç
        toggle_contents = self._get_toggle_content_blocks()

        toggle_index = 0
        for block in blocks:
            if block.get("type") == "toggle":
                if toggle_index < len(toggle_contents):
                    _, children = toggle_contents[toggle_index]
                    block_id = block.get("id")
                    if block_id and children:
                        self.notion.blocks.children.append(
                            block_id=block_id,
                            children=children
                        )
                    toggle_index += 1

    def _create_template_blocks(self) -> List[dict]:
        """–°–æ–∑–¥–∞–µ—Ç –±–ª–æ–∫–∏ —à–∞–±–ª–æ–Ω–∞ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö children)"""
        blocks = [
            # # Research
            {
                "object": "block",
                "type": "heading_1",
                "heading_1": {
                    "rich_text": [{"type": "text", "text": {"content": "Research"}}]
                }
            },
            # –ü—É—Å—Ç–æ–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {"rich_text": []}
            },
            # # Notes
            {
                "object": "block",
                "type": "heading_1",
                "heading_1": {
                    "rich_text": [{"type": "text", "text": {"content": "Notes"}}]
                }
            },
            # –ü—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞: –®—Ä–∏—Ñ—Ç—ã –¥–ª—è Linked IN
            {
                "object": "block",
                "type": "bulleted_list_item",
                "bulleted_list_item": {
                    "rich_text": [{"type": "text", "text": {"content": "–®—Ä–∏—Ñ—Ç—ã –¥–ª—è Linked IN - Time New Romans. –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ 53%"}}]
                }
            },
            # Toggle: –ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [{"type": "text", "text": {"content": "–ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"}}]
                }
            },
            # Toggle: –ü—Ä–æ–º–ø—Ç —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [{"type": "text", "text": {"content": "–¢—É—Ç —è —Ç–µ—Å—Ç–∏—Ä—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–º–ø—Ç–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º"}}]
                }
            },
            # Toggle: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–±–∑–∞—Ü–∞
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [{"type": "text", "text": {"content": "–ü—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–±–∑–∞—Ü–∞"}}]
                }
            },
            # Toggle: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º—ã
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [{"type": "text", "text": {"content": "–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º—ã"}}]
                }
            },
            # # Draft
            {
                "object": "block",
                "type": "heading_1",
                "heading_1": {
                    "rich_text": [{"type": "text", "text": {"content": "Draft"}}]
                }
            },
        ]

        return blocks

    def _get_toggle_content_blocks(self) -> List[Tuple[int, List[dict]]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è toggle –±–ª–æ–∫–æ–≤ (–±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã)

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–∏–Ω–¥–µ–∫—Å_toggle_–±–ª–æ–∫–∞, [–¥–æ—á–µ—Ä–Ω–∏–µ_–±–ª–æ–∫–∏])
        """
        return [
            # –ü—Ä–æ–º–ø—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–∏–Ω–¥–µ–∫—Å 4)
            (4, [
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{"type": "text", "text": {"content": """–í —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∏–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –°—Å—ã–ª–∫–∞ –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –î–∞—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏

–ê–≥—Ä–µ–≥–∏—Ä—É–π —ç—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –¥–∞—Ç–µ –≤ —Ñ–æ—Ä–º–µ—Ç

–î–∞—Ç–∞

–°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π

–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏ –Ω–µ –º–µ–Ω—è–π. –°—Å—ã–ª–∫—É –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ–±–∞–≤—å –≤–æ –≤–Ω—É—Ç—Ä—å –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏.  –î–∞—Ç—É –∏–∑–º–µ–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É."""}}]
                    }
                }
            ]),
            # –ü—Ä–æ–º–ø—Ç —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º (–∏–Ω–¥–µ–∫—Å 5)
            (5, [
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{"type": "text", "text": {"content": """–í —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∏–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –°—Å—ã–ª–∫–∞ –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –î–∞—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏

–ê–≥—Ä–µ–≥–∏—Ä—É–π —ç—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –¥–∞—Ç–µ –≤ —Ñ–æ—Ä–º–µ—Ç

–î–∞—Ç–∞

–°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π

–°—Å—ã–ª–∫—É –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ–±–∞–≤—å –≤–æ –≤–Ω—É—Ç—Ä—å –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏.  –î–∞—Ç—É –∏–∑–º–µ–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É. –ù–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π.

–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å–ª–æ–≤–Ω—ã–º, –æ–Ω –¥–æ–∂–µ–Ω  –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å–º—ã—Å–ª —Å—Ç–∞—Ç—å–∏ –∏ –±—ã—Ç—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ–¥ —Ä—É—Å—Å–∫–æ–≥–æ–≤–æ—Ä—è—â–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞.  –ò—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏—Ü–∏–∑–º—ã –≤ –ø–µ—Ä–µ–≤–æ–¥–µ —Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –≤–µ—è–Ω–∏—è–º —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–≥–π –º–æ–¥—ã. –ò–∑–º–µ–Ω—è–π –≥—Ä–∞–º–∞—Ç–∏–∫—É –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫—É —Å–ª–æ–≤  —Ç–∞–∫ —á—Ç–æ –±—ã —Ç–≤–æ–π –ø–µ—Ä–µ–≤–æ–ª –≤—ã–≥–ª—è–¥–µ–ª –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ. –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ –¥–æ–ª–∂–µ–Ω –≤—ã–≥–ª—è–¥–∏—Ç —Ç–æ–ø–æ—Ä–Ω–æ, –æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º –∏ –∏–∑–æ–±—Ä–∏—Ç–µ—Ç–µ–ª—å–Ω—ã–º."""}}]
                    }
                }
            ]),
            # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–±–∑–∞—Ü–∞ (–∏–Ω–¥–µ–∫—Å 6)
            (6, [
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{"type": "text", "text": {"content": "–û—Ç–ª–∏—á–Ω–æ, —Ç–µ–ø–µ—Ä—å —Ç—ã –¥–æ–∂–µ–Ω —Å–æ—Å—Ç–∞–≤–∏—Ç—å –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω—ã–π –∞–±–∑–∞—Ü –¥–ª—è –¥–∞–π–∂–µ—Å—Ç–≤–∞ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–º. –í–æ –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–º –∞–±–∞—Ü–µ –Ω—É–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å 3 –ø—Ä–æ–∏–∑–≤–æ–ª–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–∏ –∫—Ä–∞—Ç–∫–æ —Ä–∞—Å—Å–∫–∞–∑–∞–≤ –æ –Ω–∏—Ö. –ù–æ–≤–æ—Å—Ç–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω—ã—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –¥–∞—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞."}}]
                    }
                }
            ]),
            # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º—ã (–∏–Ω–¥–µ–∫—Å 7)
            (7, [
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{"type": "text", "text": {"content": "–ü—Ä–∏–¥—É–º–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏ –∫–æ—Ç–æ—Ä–æ–µ –±—ã –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ –æ–ø–∏—Å—ã–≤–≤–∞–∞–ª–∞ —Å—É—Ç—å —ç—Ç–æ–π —Å—Ç–∞—Ç—å. –í–æ—Ç –ø—Ä–∏–º–µ—Ä —Ö–æ—Ä–æ—à–µ–π —Ç–µ–º—ã **Google –æ–±–Ω–æ–≤–∏–ª–∞ Gemini 2.5 Pro - —Ç–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–ª–æ–∂–Ω—ã–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏**"}}]
                    }
                }
            ]),
        ]

    def fetch_news_from_database(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ Database "–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
        –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥

        Args:
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–ª—è–º–∏ name, url, date
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
        filter_params = {
            "and": [
                {
                    "property": "Date",
                    "date": {
                        "on_or_after": start_date.strftime("%Y-%m-%d")
                    }
                },
                {
                    "property": "Date",
                    "date": {
                        "on_or_before": end_date.strftime("%Y-%m-%d")
                    }
                }
            ]
        }

        news_items = []
        has_more = True
        next_cursor = None

        while has_more:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
            body = {
                "filter": filter_params,
                "sorts": [
                    {
                        "property": "Date",
                        "direction": "descending"
                    }
                ]
            }

            if next_cursor:
                body["start_cursor"] = next_cursor

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º httpx –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ Notion API
            headers = {
                "Authorization": f"Bearer {self.notion_token}",
                "Content-Type": "application/json",
                "Notion-Version": "2022-06-28"
            }

            with httpx.Client() as client:
                api_response = client.post(
                    f"https://api.notion.com/v1/databases/{self.news_db_id}/query",
                    headers=headers,
                    json=body,
                    timeout=30.0
                )
                api_response.raise_for_status()
                response = api_response.json()

            for page in response.get("results", []):
                properties = page.get("properties", {})

                # –ò–∑–≤–ª–µ–∫–∞–µ–º Name (title)
                name = ""
                name_prop = properties.get("Name", {})
                if name_prop.get("type") == "title":
                    title_array = name_prop.get("title", [])
                    name = "".join([t.get("plain_text", "") for t in title_array])

                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL
                url = ""
                url_prop = properties.get("URL", {})
                if url_prop.get("type") == "url":
                    url = url_prop.get("url", "") or ""

                # –ò–∑–≤–ª–µ–∫–∞–µ–º Date
                date_str = ""
                date_prop = properties.get("Date", {})
                if date_prop.get("type") == "date":
                    date_obj = date_prop.get("date", {})
                    if date_obj and date_obj.get("start"):
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ YYYY-MM-DD –≤ DD.MM.YYYY
                        try:
                            dt = datetime.strptime(date_obj["start"], "%Y-%m-%d")
                            date_str = dt.strftime("%d.%m.%Y")
                        except:
                            date_str = date_obj["start"]

                if name:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ
                    news_items.append({
                        "name": name,
                        "url": url,
                        "date": date_str
                    })

            has_more = response.get("has_more", False)
            next_cursor = response.get("next_cursor")

        return news_items

    def aggregate_news_by_date(self, news_items: List[Dict]) -> Dict[str, List[Dict]]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –¥–∞—Ç–∞–º

        Args:
            news_items: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å {–¥–∞—Ç–∞: [–Ω–æ–≤–æ—Å—Ç–∏]}
        """
        aggregated = defaultdict(list)

        for item in news_items:
            date = item.get("date", "–ë–µ–∑ –¥–∞—Ç—ã")
            aggregated[date].append(item)

        return dict(aggregated)

    def format_news_as_markdown_blocks(self, aggregated_news: Dict[str, List[Dict]]) -> List[dict]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –±–ª–æ–∫–∏ Notion

        Args:
            aggregated_news: –°–ª–æ–≤–∞—Ä—å {–¥–∞—Ç–∞: [–Ω–æ–≤–æ—Å—Ç–∏]}

        Returns:
            –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ Notion
        """
        blocks = []

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        sorted_dates = sorted(
            aggregated_news.keys(),
            key=lambda x: datetime.strptime(x, "%d.%m.%Y") if x != "–ë–µ–∑ –¥–∞—Ç—ã" else datetime.min,
            reverse=True
        )

        for date in sorted_dates:
            news_list = aggregated_news[date]

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –¥–∞—Ç–æ–π (### DD.MM.YYYY)
            blocks.append({
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": date}}]
                }
            })

            # –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            for news in news_list:
                name = news.get("name", "")
                url = news.get("url", "")

                if url:
                    # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –≤–Ω—É—Ç—Ä–∏ –Ω–∞–∑–≤–∞–Ω–∏—è
                    blocks.append({
                        "object": "block",
                        "type": "bulleted_list_item",
                        "bulleted_list_item": {
                            "rich_text": [
                                {
                                    "type": "text",
                                    "text": {
                                        "content": name,
                                        "link": {"url": url}
                                    }
                                }
                            ]
                        }
                    })
                else:
                    # –ë–µ–∑ —Å—Å—ã–ª–∫–∏
                    blocks.append({
                        "object": "block",
                        "type": "bulleted_list_item",
                        "bulleted_list_item": {
                            "rich_text": [
                                {
                                    "type": "text",
                                    "text": {"content": name}
                                }
                            ]
                        }
                    })

            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {"rich_text": []}
            })

        return blocks

    def append_blocks_to_page(self, page_id: str, blocks: List[dict]):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –±–ª–æ–∫–∏ –≤ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Args:
            page_id: ID —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            blocks: –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        """
        # Notion API –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–æ 100 –±–ª–æ–∫–æ–≤ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
        batch_size = 100

        for i in range(0, len(blocks), batch_size):
            batch = blocks[i:i + batch_size]
            self.notion.blocks.children.append(
                block_id=page_id,
                children=batch
            )


def parse_date(date_str: str) -> Optional[datetime]:
    """
    –ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY

    Args:
        date_str: –°—Ç—Ä–æ–∫–∞ —Å –¥–∞—Ç–æ–π

    Returns:
        datetime –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
    """
    try:
        return datetime.strptime(date_str.strip(), "%d.%m.%Y")
    except ValueError:
        return None


def get_database_urls_from_user() -> Tuple[str, str]:
    """
    –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç URL –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        Tuple[blog_db_id, news_db_id]
    """
    print("\n" + "=" * 60)
    print("–í–≤–µ–¥–∏—Ç–µ URL –∏–ª–∏ ID –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö Notion")
    print("=" * 60)

    # –ë–∞–∑–∞ "–õ–∏—á–Ω—ã–π –±–ª–æ–≥"
    while True:
        blog_input = input("\nURL Database '–õ–∏—á–Ω—ã–π –±–ª–æ–≥': ").strip()
        if blog_input:
            blog_db_id = extract_database_id(blog_input)
            if blog_db_id and len(blog_db_id.replace('-', '')) == 32:
                break
        print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –∏–ª–∏ ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")

    # –ë–∞–∑–∞ "–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
    while True:
        news_input = input("URL Database '–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è': ").strip()
        if news_input:
            news_db_id = extract_database_id(news_input)
            if news_db_id and len(news_db_id.replace('-', '')) == 32:
                break
        print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –∏–ª–∏ ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")

    return blog_db_id, news_db_id


def get_date_range_from_user() -> Tuple[datetime, datetime]:
    """
    –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        Tuple[start_date, end_date]
    """
    print("\n" + "=" * 60)
    print("–í–≤–µ–¥–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π")
    print("–§–æ—Ä–º–∞—Ç: DD.MM.YYYY")
    print("=" * 60)

    # –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
    while True:
        start_input = input("\n–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY): ").strip()
        start_date = parse_date(start_input)
        if start_date:
            break
        print("–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY")

    # –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
    while True:
        end_input = input("–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY): ").strip()
        end_date = parse_date(end_input)
        if end_date:
            if end_date >= start_date:
                break
            print("–û—à–∏–±–∫–∞: –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å >= –Ω–∞—á–∞–ª—å–Ω–æ–π")
        else:
            print("–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY")

    return start_date, end_date


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    notion_token = os.getenv("NOTION_TOKEN")

    if len(sys.argv) > 1:
        notion_token = sys.argv[1]

    if not notion_token:
        print("–û—à–∏–±–∫–∞: NOTION_TOKEN –Ω–µ —É–∫–∞–∑–∞–Ω")
        print("\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  export NOTION_TOKEN='your_token'")
        print("  python3 create_digest.py")
        print("\n–ò–ª–∏:")
        print("  python3 create_digest.py <NOTION_TOKEN>")
        sys.exit(1)

    print("=" * 60)
    print("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ AI Digest –≤ Notion")
    print("=" * 60)

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º URL –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
    blog_db_id, news_db_id = get_database_urls_from_user()

    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
    creator = DigestCreator(notion_token, blog_db_id, news_db_id)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä –Ω–µ–¥–µ–ª–∏ –∏ –≥–æ–¥
    week_number, year = creator.get_current_week_info()

    print(f"\nüìÖ –¢–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è: {week_number}, –ì–æ–¥: {year}")
    print(f"üìù –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: AI Digest - Week {week_number} {year}")

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
    start_date, end_date = get_date_range_from_user()

    print(f"\nüìä –ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {start_date.strftime('%d.%m.%Y')} - {end_date.strftime('%d.%m.%Y')}")

    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? [y/N]: ").strip().lower()
    if confirm not in ['y', 'yes', '–¥–∞', '–¥']:
        print("–û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        sys.exit(0)

    # –®–∞–≥ 1: –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
    print("\n" + "-" * 60)
    print("üìÑ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ Database '–õ–∏—á–Ω—ã–π –±–ª–æ–≥'...")

    try:
        page_id = creator.create_digest_page(week_number, year)
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞! ID: {page_id}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        sys.exit(1)

    # –®–∞–≥ 2: –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏
    print("\n" + "-" * 60)
    print("üì∞ –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ Database '–û–±–∑–æ—Ä —Ä—ã–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è'...")

    try:
        news_items = creator.fetch_news_from_database(start_date, end_date)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_items)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        sys.exit(1)

    if not news_items:
        print("‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–µ–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        print("–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—É—Å—Ç–æ–π —Å–µ–∫—Ü–∏–µ–π Draft.")
        sys.exit(0)

    # –®–∞–≥ 3: –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–∞–º
    print("\n" + "-" * 60)
    print("üìä –ê–≥—Ä–µ–≥–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –¥–∞—Ç–∞–º...")

    aggregated = creator.aggregate_news_by_date(news_items)
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç: {len(aggregated)}")

    for date, items in sorted(aggregated.items(), key=lambda x: datetime.strptime(x[0], "%d.%m.%Y") if x[0] != "–ë–µ–∑ –¥–∞—Ç—ã" else datetime.min, reverse=True):
        print(f"   {date}: {len(items)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –®–∞–≥ 4: –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    print("\n" + "-" * 60)
    print("üìù –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Å–µ–∫—Ü–∏—é Draft...")

    try:
        news_blocks = creator.format_news_as_markdown_blocks(aggregated)
        creator.append_blocks_to_page(page_id, news_blocks)
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –±–ª–æ–∫–æ–≤: {len(news_blocks)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
        sys.exit(1)

    # –ì–æ—Ç–æ–≤–æ
    print("\n" + "=" * 60)
    print("üéâ AI Digest —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
    print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞: AI Digest - Week {week_number} {year}")
    print(f"üîó ID: {page_id}")
    print("=" * 60)

    # –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π
    print("\n" + "-" * 60)
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π...")

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –ª–æ–≥-—Ñ–∞–π–ª–∞ —Å –¥–∞—Ç–æ–π –∏ –Ω–æ–º–µ—Ä–æ–º –Ω–µ–¥–µ–ª–∏
    log_filename = f"title_verification_week{week_number}_{year}.log"
    verifier = TitleVerifier(max_concurrent=5)
    mismatches = verifier.verify_titles(news_items, log_file=log_filename)

    print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {log_filename}")

    if mismatches:
        print(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {len(mismatches)}")
        print("-" * 60)
        for i, mismatch in enumerate(mismatches, 1):
            print(f"\n{i}. URL: {mismatch['url']}")
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ –≤ Digest: {mismatch['name']}")
            if mismatch.get('error'):
                print(f"   –û—à–∏–±–∫–∞: {mismatch['error']}")
            else:
                print(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {mismatch['actual_title']}")
    else:
        print("‚úÖ –í—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∞–º —Å—Ç–∞—Ç–µ–π")


if __name__ == "__main__":
    main()
